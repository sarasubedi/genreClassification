{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afaccad0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This Jupyter Notebook is designed to preprocess and prepare data for machine learning tasks, specifically for classifying songs as R&B or not. The workflow involves several steps, including data loading, feature extraction, and merging datasets. Below is an overview of the key steps:\n",
    "\n",
    "1. **Data Loading**:\n",
    "    - The dataset is loaded from a `.tsv` file located at `../../data/acousticbrainz-mediaeval_labels...`.\n",
    "    - The dataset contains metadata about songs, including genres and identifiers.\n",
    "\n",
    "2. **Label Creation**:\n",
    "    - A new column, `is_rnb`, is created to label songs as R&B (1) or not (0) based on genre information.\n",
    "\n",
    "3. **Feature Extraction**:\n",
    "    - Features are extracted from JSON files located in the folder `../../data/acousticbrainz-mediaeval-train`.\n",
    "    - These features include timbre, tonal, rhythm, and spectral properties of the songs.\n",
    "\n",
    "4. **Data Merging**:\n",
    "    - The extracted features are merged with the labeled dataset using the `recordingmbid` column as the key.\n",
    "\n",
    "5. **Output**:\n",
    "    - The final merged dataset is saved as a CSV file (`tmp/rnb_features_labeled.csv`) for further analysis or modeling.\n",
    "\n",
    "This notebook provides a structured approach to preprocess raw data into a format suitable for machine learning, ensuring that the features and labels are aligned and ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9310612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb0f7a",
   "metadata": {},
   "source": [
    "### Reading Data from File\n",
    "\n",
    "The dataset is loaded from a `.tsv` file located at `../../data/acousticbrainz-mediaeval_labels...`. This file contains metadata about songs, including genres and identifiers. The data is read into a pandas DataFrame for further processing.\n",
    "\n",
    "> takes about 30s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41858bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/ms365n9s4t3fp5htj9nxj83w0000gn/T/ipykernel_22661/896122043.py:3: DtypeWarning: Columns (15,16,17,18,19,20,21,22,23,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_a = pd.read_csv(datapath + 'a', delimiter='\\t')\n",
      "/var/folders/6z/ms365n9s4t3fp5htj9nxj83w0000gn/T/ipykernel_22661/896122043.py:4: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_b = pd.read_csv(datapath + 'b', delimiter='\\t')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['recordingmbid', 'releasegroupmbid', 'genre1', 'genre2', 'genre3',\n",
       "       'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10',\n",
       "       'genre11', 'genre12', 'genre13', 'genre14', 'genre15', 'genre16',\n",
       "       'genre17', 'genre18', 'genre19', 'genre20', 'genre21', 'genre22',\n",
       "       'genre23', 'genre24', 'genre25', 'genre26', 'genre27', 'genre28',\n",
       "       'genre29', 'genre30', 'is_rnb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = '../data/acousticbrainz-mediaeval_labels_part_a'\n",
    "\n",
    "data_a = pd.read_csv(datapath + 'a', delimiter='\\t')\n",
    "data_b = pd.read_csv(datapath + 'b', delimiter='\\t')\n",
    "\n",
    "data = pd.concat([data_a, data_b], ignore_index=True)\n",
    "\n",
    "# uncomment below if you wnat to enter a differnet file for data\n",
    "# datapath = '../../data/[filename]'\n",
    "# data = pd.read_csv(datapath, delimiter='\\t')\n",
    "\n",
    "# labels the songs that are rnb as is_rnb\n",
    "data['is_rnb'] = data.filter(like='genre').apply(lambda x: x.astype(str).str.contains(r'R&B|rnb|r&b_soul|r\\'n\\'b', case=False, na=False)).any(axis=1).astype(int)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4b3a1",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns\n",
    "\n",
    "To simplify the dataset and focus on relevant features, unnecessary columns such as `releasegroupmbid`, `genre1`, `genre2`, ..., `genre30` are dropped from the `data` DataFrame. This reduces dimensionality and ensures only essential information is retained for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba8b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_rnb\n",
      "0    896896\n",
      "1      8048\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# only need the lables for if it is rnb and song identifier\n",
    "data_labeled = data[['recordingmbid', 'is_rnb']]\n",
    "print(data_labeled['is_rnb'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7cfdb",
   "metadata": {},
   "source": [
    "### Helper Functions Description\n",
    "\n",
    "The following helper functions are used to process and extract features from JSON files containing song data:\n",
    "\n",
    "1. **`extract_features_from_json(data)`**:\n",
    "    - **Purpose**: Extracts various audio features from a JSON object.\n",
    "    - **Details**:\n",
    "        - Extracts timbre features such as MFCC and GFCC means.\n",
    "        - Includes tonal features like chords change rate, key scale, pitch salience, and dissonance.\n",
    "        - Captures rhythm features like BPM and onset rate.\n",
    "        - Extracts spectral features such as centroid, complexity, rolloff, flux, zero-crossing rate, and spectral contrast coefficients.\n",
    "        - Includes dynamics, rhythm extensions, energy band shapes, harmonic structure, and tonal energy balance.\n",
    "    - **Error Handling**: Prints a message if a key is missing in the JSON data.\n",
    "\n",
    "2. **`build_feature_labels(data_sample)`**:\n",
    "    - **Purpose**: Generates a list of feature labels based on the structure of the JSON data.\n",
    "    - **Details**:\n",
    "        - Creates labels for MFCC and GFCC coefficients.\n",
    "        - Adds labels for other extracted features such as chords change rate, key scale, pitch salience, spectral features, and dynamics.\n",
    "        - Ensures the labels align with the extracted features for consistency in the DataFrame.\n",
    "\n",
    "3. **`process_dataset(root_folder)`**:\n",
    "    - **Purpose**: Processes all JSON files in a given folder to extract features and compile them into a DataFrame.\n",
    "    - **Details**:\n",
    "        - Iterates through all JSON files in the specified folder.\n",
    "        - Extracts features using `extract_features_from_json`.\n",
    "        - Initializes feature labels using `build_feature_labels` for the first valid JSON file.\n",
    "        - Compiles all extracted features into a pandas DataFrame with appropriate labels.\n",
    "        - Adds a `recordingmbid` column to associate features with song identifiers.\n",
    "    - **Error Handling**: Prints a message if a file fails to process due to an exception.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f71f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to pull features from the JSON files\n",
    "\n",
    "def extract_features_from_json(data):\n",
    "    try:\n",
    "        features = []\n",
    "\n",
    "        # Timbre\n",
    "        features += data['lowlevel']['mfcc']['mean']\n",
    "        features += data['lowlevel']['gfcc']['mean']\n",
    "        features.append(data['lowlevel']['hfc']['mean'])\n",
    "\n",
    "        # Tonal - Harmony\n",
    "        features.append(data['tonal']['chords_changes_rate'])        \n",
    "\n",
    "        # Tonal - Scale (major=0, minor=1)\n",
    "        scale = data['tonal'].get('key_scale', 'major')\n",
    "        features.append(1 if scale == 'minor' else 0)\n",
    "\n",
    "        # Tonal - Pitch salience & dissonance\n",
    "        features.append(data['lowlevel']['pitch_salience']['mean'])\n",
    "        features.append(data['lowlevel']['dissonance']['mean'])\n",
    "\n",
    "        # Rhythm\n",
    "        features.append(data['rhythm']['bpm'])\n",
    "        features.append(data['rhythm']['onset_rate'])\n",
    "\n",
    "        # Spectrum\n",
    "        features.append(data['lowlevel']['spectral_centroid']['mean'])\n",
    "        features.append(data['lowlevel']['spectral_complexity']['mean'])\n",
    "        features.append(data['lowlevel']['spectral_rolloff']['mean'])\n",
    "        features.append(data['lowlevel']['spectral_flux']['mean'])\n",
    "        features.append(data['lowlevel']['zerocrossingrate']['mean'])\n",
    "\n",
    "        # Spectral contrast (6D, not contrast_coeffs)\n",
    "        features += data['lowlevel']['spectral_contrast_coeffs']['mean']\n",
    "\n",
    "        # Dynamics\n",
    "        features.append(data['lowlevel']['average_loudness'])\n",
    "        features.append(data['lowlevel']['dynamic_complexity'])\n",
    "\n",
    "        # Rhythm extension\n",
    "        features.append(data['rhythm']['beats_loudness']['mean'])\n",
    "\n",
    "        # Energy band shape\n",
    "        features.append(data['lowlevel']['spectral_energyband_low']['mean'])\n",
    "        features.append(data['lowlevel']['spectral_energyband_high']['mean'])\n",
    "\n",
    "        # Harmonic structure\n",
    "        features.append(data['tonal']['hpcp_entropy']['mean'])\n",
    "        features.append(data['tonal']['key_strength'])\n",
    "\n",
    "        # Tonal energy balance\n",
    "        features.append(data['lowlevel']['spectral_entropy']['mean'])\n",
    "        features.append(data['lowlevel']['spectral_strongpeak']['mean'])\n",
    "\n",
    "        return features\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key: {e}\")\n",
    "        return None\n",
    "    \n",
    "def build_feature_labels(data_sample):\n",
    "    labels = []\n",
    "\n",
    "    labels += [f\"mfcc_{i}\" for i in range(len(data_sample['lowlevel']['mfcc']['mean']))]\n",
    "    labels += [f\"gfcc_{i}\" for i in range(len(data_sample['lowlevel']['gfcc']['mean']))]\n",
    "    labels += [\"hfc\"]\n",
    "    labels += [\"chords_changes_rate\"]\n",
    "    \n",
    "    labels += [\"key_scale\"]\n",
    "    labels += [\"pitch_salience\"]\n",
    "    labels += [\"dissonance\"]\n",
    "    labels += [\"bpm\", \"onset_rate\"]\n",
    "    labels += [\"spectral_centroid\", \"spectral_complexity\", \"spectral_rolloff\", \"spectral_flux\", \"zerocrossingrate\"]\n",
    "    labels += [f\"spectral_contrast_{i}\" for i in range(len(data_sample['lowlevel']['spectral_contrast_coeffs']['mean']))]\n",
    "    labels += [\"average_loudness\", \"dynamic_complexity\"]\n",
    "\n",
    "    labels += [\"beats_loudness\"]\n",
    "    labels += [\"spectral_energyband_low\", \"spectral_energyband_high\"]\n",
    "    labels += [\"hpcp_entropy\", \"key_strength\"]\n",
    "    labels += [\"spectral_entropy\", \"spectral_strongpeak\"]\n",
    "\n",
    "    return labels\n",
    "\n",
    "def process_dataset(root_folder):\n",
    "    all_features = []\n",
    "    file_ids = []\n",
    "    labels_initialized = False\n",
    "    feature_labels = []\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    features = extract_features_from_json(data)\n",
    "                    if features is None:\n",
    "                        continue\n",
    "\n",
    "                    if not labels_initialized:\n",
    "                        feature_labels = build_feature_labels(data)\n",
    "                        labels_initialized = True\n",
    "\n",
    "                    all_features.append(features)\n",
    "                    file_ids.append(file.replace('.json', ''))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed on {file}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_features, columns=feature_labels)\n",
    "    df['recordingmbid'] = file_ids\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc581e",
   "metadata": {},
   "source": [
    "### Feature Extraction Using Helper Functions\n",
    "\n",
    "The feature extraction process involves using the helper functions defined earlier to extract audio features from JSON files. These features include timbre, tonal, rhythm, and spectral properties of the songs. The steps are as follows:\n",
    "The resulting DataFrame (`data_features`) contains the extracted features for all songs, which are then merged with the labeled dataset (`data_labeled`) to create the final dataset (`merged_df`) for further analysis or modeling.\n",
    "\n",
    "> takes about 4 mins at most\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract JSON features \n",
    "folder_path = '../data/acousticbrainz-mediaeval-train'\n",
    "data_features = process_dataset(folder_path)\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc6b57",
   "metadata": {},
   "source": [
    "### Creating a Comprehensive DataFrame with Features and Labels\n",
    "\n",
    "To create a comprehensive DataFrame that combines all extracted features and their corresponding labels, we merge the `data_features` DataFrame (containing the extracted features) with the `data_labeled` DataFrame (containing the labels). This ensures that each song's features are aligned with its label (`is_rnb`).\n",
    "\n",
    "The resulting DataFrame, `merged_df`, contains both the features and the labels, making it ready for further analysis or machine learning tasks.\n",
    "\n",
    "> Finally, the merged DataFrame is saved to a CSV file (`tmp/rnb_features_labeled.csv`) for later use in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c74d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [recordingmbid, is_rnb]\n",
      "Index: []\n",
      "Shape: (0, 2)\n",
      "Label value counts:\n",
      " Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(data_features, data_labeled, on=\"recordingmbid\", how=\"inner\")\n",
    "\n",
    "# Check results\n",
    "print(merged_df.head())\n",
    "print(\"Shape:\", merged_df.shape)\n",
    "print(\"Label value counts:\\n\", merged_df['is_rnb'].value_counts())\n",
    "\n",
    "merged_df.to_csv(\"tmp/rnb_features_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed463d",
   "metadata": {},
   "source": [
    "### Using the Processed Dataset for Modeling\n",
    "\n",
    "To use the processed dataset for your own machine learning model, follow these steps:\n",
    "\n",
    "1. **Read the CSV File**:\n",
    "    - The processed dataset has been saved as `tmp/rnb_features_labeled.csv`.\n",
    "    - Use `pandas` to read the CSV file into a DataFrame.\n",
    "\n",
    "2. **Separate Features and Labels**:\n",
    "    - The dataset contains both features and labels (`is_rnb`).\n",
    "    - Separate the features (`X`) and labels (`y`) for training your model.\n",
    "\n",
    "3. **Use the DataFrame for Modeling**:\n",
    "    - The `X` DataFrame contains the features, and `y` contains the labels.\n",
    "    - Use these to train your machine learning model.\n",
    "\n",
    "    Example:\n",
    "    - Split the data into training and testing sets.\n",
    "    - Train a model.\n",
    "    - Make predictions and evaluate the model's accuracy.\n",
    "\n",
    "By following these steps, you can easily load the processed dataset and use it to train and evaluate your own machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "df = pd.read_csv(\"tmp/rnb_features_labeled.csv\")\n",
    "\n",
    "# Separate features (X) and labels (y) for the dataset\n",
    "X = df.drop(columns=['recordingmbid', 'is_rnb'])\n",
    "y = df['is_rnb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348defd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
